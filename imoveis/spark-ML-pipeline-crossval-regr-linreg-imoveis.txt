
val df = spark.read.json("spark/imoveis/imoveis.json")

spark.conf.set("spark.sql.shuffle.partitions",6)

df.printSchema
root
 |-- ident: struct (nullable = true)
 |    |-- customerID: string (nullable = true)
 |    |-- source: string (nullable = true)
 |-- listing: struct (nullable = true)
 |    |-- address: struct (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- location: struct (nullable = true)
 |    |    |    |-- lat: double (nullable = true)
 |    |    |    |-- lon: double (nullable = true)
 |    |    |-- neighborhood: string (nullable = true)
 |    |    |-- zone: string (nullable = true)
 |    |-- features: struct (nullable = true)
 |    |    |-- bathrooms: long (nullable = true)
 |    |    |-- bedrooms: long (nullable = true)
 |    |    |-- floors: long (nullable = true)
 |    |    |-- parkingSpaces: long (nullable = true)
 |    |    |-- suites: long (nullable = true)
 |    |    |-- totalAreas: string (nullable = true)
 |    |    |-- unitFloor: long (nullable = true)
 |    |    |-- unitsOnTheFloor: long (nullable = true)
 |    |    |-- usableAreas: string (nullable = true)
 |    |-- prices: struct (nullable = true)
 |    |    |-- price: string (nullable = true)
 |    |    |-- tax: struct (nullable = true)
 |    |    |    |-- condo: string (nullable = true)
 |    |    |    |-- iptu: string (nullable = true)
 |    |-- types: struct (nullable = true)
 |    |    |-- unit: string (nullable = true)
 |    |    |-- usage: string (nullable = true)
 
df.show(10,false)
+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
|ident                     |listing                                                                                                                                                          |
+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[775564-BOJSMVON, Website]|[[Rio de Janeiro, [-22.909429, -43.413557], Taquara, Zona Oeste], [0, 0, 0, 1, 0, 62, 0, 0, 62], [45000, [150, 0]], [Outros, Residencial]]                       |
|[660895-AUENKNYY, Website]|[[Rio de Janeiro, [-22.869698, -43.509141], Santíssimo, Zona Oeste], [1, 2, 0, 1, 0, 0, 0, 0, 44], [45000, [120, 0]], [Apartamento, Residencial]]                |
|[751522-JESYFEQL, Website]|[[Rio de Janeiro, [-22.986927, -43.646786], Pedra de Guaratiba, Zona Oeste], [0, 0, 0, 0, 0, 132, 0, 0, 132], [50000, [100, 0]], [Outros, Residencial]]          |
|[714052-GAAEWYKS, Website]|[[Rio de Janeiro, [-22.881977, -43.330818], Cascadura, Zona Norte], [1, 0, 0, 0, 0, 32, 3, 0, 32], [45000, [468, 346]], [Outros, Comercial]]                     |
|[568886-ZIBFOMCC, Website]|[[Rio de Janeiro, [-23.027653, -43.480742], Recreio dos Bandeirantes, Zona Oeste], [2, 3, 3, 1, 1, 0, 2, 4, 60], [50000, [400, 120]], [Apartamento, Residencial]]|
|[526755-OBLTYTEN, Website]|[[Rio de Janeiro, [-22.966059, -43.571183], Guaratiba, Zona Oeste], [0, 0, 0, 0, 0, 200, 0, 0, 200], [50000, [0,]], [Outros, Residencial]]                       |
|[593569-CJLMNFGW, Website]|[[Rio de Janeiro, [-22.939028, -43.3453], Freguesia (Jacarepaguá), Zona Oeste], [1, 0, 0, 0, 0, 25, 2, 0, 25], [50000, [801, 211]], [Outros, Comercial]]         |
|[989181-RYJOLMCU, Website]|[[Rio de Janeiro, [-22.841509, -43.278855], Penha, Zona Norte], [1, 0, 0, 0, 0, 23, 0, 0, 23], [50000, [230,]], [Outros, Comercial]]                             |
|[145372-EZKAKSWM, Website]|[[Rio de Janeiro, [-22.835609, -43.392253], Ricardo de Albuquerque, Zona Norte], [0, 0, 0, 0, 0, 60, 0, 0, 60], [45000, [,]], [Outros, Comercial]]               |
|[792086-NWNQTDYL, Website]|[[Rio de Janeiro, [-22.885306, -43.253044], Jacarezinho, Zona Norte], [1, 1, 0, 1, 0, 35, 0, 0, 33], [45336, [0, 0]], [Apartamento, Residencial]]                |
+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
only showing top 10 rows

df.select("listing.address.city","listing.address.zone","listing.features.*","listing.prices.price","listing.types.*").show(10)
+--------------+----------+---------+--------+------+-------------+------+----------+---------+---------------+-----------+-----+-----------+-----------+
|          city|      zone|bathrooms|bedrooms|floors|parkingSpaces|suites|totalAreas|unitFloor|unitsOnTheFloor|usableAreas|price|       unit|      usage|
+--------------+----------+---------+--------+------+-------------+------+----------+---------+---------------+-----------+-----+-----------+-----------+
|Rio de Janeiro|Zona Oeste|        0|       0|     0|            1|     0|        62|        0|              0|         62|45000|     Outros|Residencial|
|Rio de Janeiro|Zona Oeste|        1|       2|     0|            1|     0|         0|        0|              0|         44|45000|Apartamento|Residencial|
|Rio de Janeiro|Zona Oeste|        0|       0|     0|            0|     0|       132|        0|              0|        132|50000|     Outros|Residencial|
|Rio de Janeiro|Zona Norte|        1|       0|     0|            0|     0|        32|        3|              0|         32|45000|     Outros|  Comercial|
|Rio de Janeiro|Zona Oeste|        2|       3|     3|            1|     1|         0|        2|              4|         60|50000|Apartamento|Residencial|
|Rio de Janeiro|Zona Oeste|        0|       0|     0|            0|     0|       200|        0|              0|        200|50000|     Outros|Residencial|
|Rio de Janeiro|Zona Oeste|        1|       0|     0|            0|     0|        25|        2|              0|         25|50000|     Outros|  Comercial|
|Rio de Janeiro|Zona Norte|        1|       0|     0|            0|     0|        23|        0|              0|         23|50000|     Outros|  Comercial|
|Rio de Janeiro|Zona Norte|        0|       0|     0|            0|     0|        60|        0|              0|         60|45000|     Outros|  Comercial|
|Rio de Janeiro|Zona Norte|        1|       1|     0|            1|     0|        35|        0|              0|         33|45336|Apartamento|Residencial|
+--------------+----------+---------+--------+------+-------------+------+----------+---------+---------------+-----------+-----+-----------+-----------+
only showing top 10 rows

val df1 = df.select("listing.address.city","listing.address.zone","listing.features.*","listing.prices.price","listing.types.*")

df1.printSchema
root
 |-- city: string (nullable = true)
 |-- zone: string (nullable = true)
 |-- bathrooms: long (nullable = true)
 |-- bedrooms: long (nullable = true)
 |-- floors: long (nullable = true)
 |-- parkingSpaces: long (nullable = true)
 |-- suites: long (nullable = true)
 |-- totalAreas: string (nullable = true)
 |-- unitFloor: long (nullable = true)
 |-- unitsOnTheFloor: long (nullable = true)
 |-- usableAreas: string (nullable = true)
 |-- price: string (nullable = true)
 |-- unit: string (nullable = true)
 |-- usage: string (nullable = true)
 
df1.groupBy("city","zone").count.orderBy("city","zone").show
+------------------+------------+-----+
|              city|        zone|count|
+------------------+------------+-----+
|Armação dos Búzios|            |    1|
|      Cachoeirinha|            |    1|
|         Queimados|            |    3|
|    Rio de Janeiro|            |  157|
|    Rio de Janeiro|Zona Central| 1921|
|    Rio de Janeiro|  Zona Norte|15191|
|    Rio de Janeiro|  Zona Oeste|37116|
|    Rio de Janeiro|    Zona Sul|19222|
|       São Gonçalo|            |    2|
|São João de Meriti|            |    1|
+------------------+------------+-----+

df1.groupBy("unit","usage").count.orderBy("unit","usage").show
+-----------+-----------+-----+
|       unit|      usage|count|
+-----------+-----------+-----+
|Apartamento|Residencial|59106|
|       Casa|  Comercial|   89|
|       Casa|Residencial| 9300|
|     Outros|  Comercial| 3930|
|     Outros|Residencial| 1190|
+-----------+-----------+-----+


import org.apache.spark.sql.types._

val df2 = df1.where('city === "Rio de Janeiro").withColumn("label", 'price.cast(DoubleType)).withColumn("usableAreas", 'usableAreas.cast(DoubleType))

df2.printSchema
root
 |-- city: string (nullable = true)
 |-- zone: string (nullable = true)
 |-- bathrooms: long (nullable = true)
 |-- bedrooms: long (nullable = true)
 |-- floors: long (nullable = true)
 |-- parkingSpaces: long (nullable = true)
 |-- suites: long (nullable = true)
 |-- totalAreas: string (nullable = true)
 |-- unitFloor: long (nullable = true)
 |-- unitsOnTheFloor: long (nullable = true)
 |-- usableAreas: double (nullable = true)
 |-- price: string (nullable = true)
 |-- unit: string (nullable = true)
 |-- usage: string (nullable = true)
 |-- label: double (nullable = true)

df2.describe().show
+-------+--------------+--------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------+-----------+------------------+
|summary|          city|    zone|         bathrooms|          bedrooms|            floors|     parkingSpaces|            suites|        totalAreas|         unitFloor|   unitsOnTheFloor|       usableAreas|             price|       unit|      usage|             label|
+-------+--------------+--------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------+-----------+------------------+
|  count|         73607|   73607|             73607|             73607|             73607|             73607|             73607|             73607|             73607|             73607|             73607|             73607|      73607|      73607|             73607|
|   mean|          null|    null|2.3723830613936174|2.5739128072058364|1.9321531919518524|1.4089013273194126|1.0746668115804203|1688.8303014658932|1.4936758732185798|1.2206447756327523|141.53970410422923| 1210756.481095548|       null|       null| 1210756.481095548|
| stddev|          null|    null|1.5336128330520953|1.2810480003465383|4.5291628898620795|1.7274123968255584| 1.177352606905103|173402.82602165386|13.118027293968664|3.4139172865327154|146.72952223609585|1384781.5939764515|       null|       null|1384781.5939764515|
|    min|Rio de Janeiro|        |                 0|                 0|                 0|                 0|                 0|                 0|                 0|                 0|               0.0|            100000|Apartamento|  Comercial|           45000.0|
|    max|Rio de Janeiro|Zona Sul|                49|                50|                50|               180|                50|               999|              1234|                76|            1917.0|           9999999|     Outros|Residencial|             1.0E7|
+-------+--------------+--------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------+-----------+------------------+


import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}

val stridx1 = new StringIndexer().setInputCol("unit").setOutputCol("unitIdx")
val stridx2 = new StringIndexer().setInputCol("usage").setOutputCol("usageIdx")
val stridx3 = new StringIndexer().setInputCol("zone").setOutputCol("zoneIdx")

val ohevect1 = new OneHotEncoder().setInputCol("unitIdx").setOutputCol("unitVect")
val ohevect2 = new OneHotEncoder().setInputCol("usageIdx").setOutputCol("usageVect")
val ohevect3 = new OneHotEncoder().setInputCol("zoneIdx").setOutputCol("zoneVect")

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("zoneIdx","bathrooms","bedrooms","floors","parkingSpaces","suites","unitFloor","unitsOnTheFloor","usableAreas","unitIdx","usageIdx"))

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(stridx1,stridx2,stridx3,va))

val df3 = pipeline.fit(df2).transform(df2)

df3.printSchema
root
 |-- city: string (nullable = true)
 |-- zone: string (nullable = true)
 |-- bathrooms: long (nullable = true)
 |-- bedrooms: long (nullable = true)
 |-- floors: long (nullable = true)
 |-- parkingSpaces: long (nullable = true)
 |-- suites: long (nullable = true)
 |-- totalAreas: string (nullable = true)
 |-- unitFloor: long (nullable = true)
 |-- unitsOnTheFloor: long (nullable = true)
 |-- usableAreas: double (nullable = true)
 |-- price: string (nullable = true)
 |-- unit: string (nullable = true)
 |-- usage: string (nullable = true)
 |-- label: double (nullable = true)
 |-- unitIdx: double (nullable = false)
 |-- usageIdx: double (nullable = false)
 |-- zoneIdx: double (nullable = false)
 |-- features: vector (nullable = true)
 
df3.select("label","features").show(10,false)
+-------+----------------------------------------------+
|label  |features                                      |
+-------+----------------------------------------------+
|45000.0|(11,[4,8,9],[1.0,62.0,2.0])                   |
|45000.0|(11,[1,2,4,8],[1.0,2.0,1.0,44.0])             |
|50000.0|(11,[8,9],[132.0,2.0])                        |
|45000.0|(11,[0,1,6,8,9,10],[2.0,1.0,3.0,32.0,2.0,1.0])|
|50000.0|[0.0,2.0,3.0,3.0,1.0,1.0,2.0,4.0,60.0,0.0,0.0]|
|50000.0|(11,[8,9],[200.0,2.0])                        |
|50000.0|(11,[1,6,8,9,10],[1.0,2.0,25.0,2.0,1.0])      |
|50000.0|(11,[0,1,8,9,10],[2.0,1.0,23.0,2.0,1.0])      |
|45000.0|(11,[0,8,9,10],[2.0,60.0,2.0,1.0])            |
|45336.0|(11,[0,1,2,4,8],[2.0,1.0,1.0,1.0,33.0])       |
+-------+----------------------------------------------+
only showing top 10 rows


// -----  calculate pearson correlation to check multicolinearity

import org.apache.spark.ml.stat.Correlation
import org.apache.spark.ml.linalg.Matrix
import org.apache.spark.sql.Row

val corr = Correlation.corr(df3, "features", "pearson").head match {
   case Row(coeff: Matrix) => coeff
}
corr: org.apache.spark.ml.linalg.Matrix =
1.0                    -0.22406149340612205  ... (11 total)
-0.22406149340612205   1.0                   ...
-0.18888475915484168   0.6559360864261189    ...
0.044450632566242765   -0.0382527293632597   ...
-0.1986458601045458    0.4048244341765544    ...
-0.31998592153709216   0.7375019444637959    ...
-8.663763931006387E-4  0.007057211256796193  ...
0.043368347757720555   -0.09841586066763162  ...
-0.16681811191470333   0.5629732349901702    ...
0.030995863303815988   0.02241616001374928   ...
0.13856800562274557    -0.13992232049394293  ...


corr.toDense.rowIter.foreach( x => {
  val size = x.size
  for ( i <- Range(0,size)) { 
    val elem = x(i)
    print(f"$elem%.3f\t") 
  }
  println
})
// "zoneIdx","bathrooms","bedrooms","floors","parkingSpaces","suites","unitFloor","unitsOnTheFloor","usableAreas","unitIdx","usageIdx"
1.000   -0.224  -0.189  0.044   -0.199  -0.320  -0.001  0.043   -0.167  0.031   0.139
-0.224  1.000   0.656   -0.038  0.405   0.738   0.007   -0.098  0.563   0.022   -0.140
-0.189  0.656   1.000   -0.064  0.340   0.600   -0.007  -0.125  0.466   -0.194  -0.390
0.044   -0.038  -0.064  1.000   -0.039  -0.042  0.125   0.671   -0.099  -0.106  -0.009
-0.199  0.405   0.340   -0.039  1.000   0.390   0.002   -0.059  0.420   0.082   -0.040
-0.320  0.738   0.600   -0.042  0.390   1.000   0.005   -0.086  0.514   -0.027  -0.198
-0.001  0.007   -0.007  0.125   0.002   0.005   1.000   0.087   -0.014  -0.023  0.001
0.043   -0.098  -0.125  0.671   -0.059  -0.086  0.087   1.000   -0.134  -0.026  0.079
-0.167  0.563   0.466   -0.099  0.420   0.514   -0.014  -0.134  1.000   0.292   0.004
0.031   0.022   -0.194  -0.106  0.082   -0.027  -0.023  -0.026  0.292   1.000   0.711
0.139   -0.140  -0.390  -0.009  -0.040  -0.198  0.001   0.079   0.004   0.711   1.000

// bathrooms x suites = 0.738 can be considered multicolinear


// ----- building the linear regression model

import org.apache.spark.ml.feature.StandardScaler
val stdScaler = new StandardScaler().
setWithStd(true).
setWithMean(true).
setInputCol("features").
setOutputCol("scaledFeatures")

import org.apache.spark.ml.regression.LinearRegression
val lr = new LinearRegression
lr.setFeaturesCol("scaledFeatures").setFitIntercept(true)

import org.apache.spark.ml.Pipeline

val pipeline = new Pipeline().setStages(Array(stridx1,stridx2,stridx3,ohevect1,ohevect2,ohevect3,va,stdScaler,lr))

val Array(trainingData, testData) = df2.randomSplit(Array(0.7,0.3),11L)

trainingData.cache
testData.cache

// ----- find best linear regression model

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

val paramGrid = new ParamGridBuilder().
addGrid(lr.regParam, Array(0.1, 0.01, 0.001)).
addGrid(lr.maxIter, Array(100,300,500)).build()

import org.apache.spark.ml.evaluation.RegressionEvaluator

val cv = new CrossValidator().
setEstimator(pipeline).
setEvaluator(new RegressionEvaluator).
setEstimatorParamMaps(paramGrid).
setNumFolds(3)

val model = cv.fit(trainingData)

import org.apache.spark.ml.PipelineModel
val bestmodel = model.bestModel.asInstanceOf[PipelineModel]

import org.apache.spark.ml.regression.LinearRegressionModel
val lrmodel = bestmodel.stages(8).asInstanceOf[LinearRegressionModel]

// -----  metrics extracted from model

lrmodel.getRegParam
res1: Double = 0.1

lrmodel.getMaxIter
res2: Int = 100

lrmodel.getFitIntercept
res4: Boolean = true

lrmodel.getStandardization
res5: Boolean = true

lrmodel.summary.rootMeanSquaredError
res24: Double = 830979.4951435948

lrmodel.summary.r2
res25: Double = 0.6405315234092093

println(s"LR Model coefficients:\n${lrmodel.coefficients.toArray.mkString("\n")}")
LR Model coefficients:
36571.18709004051
427281.4403519215
-4867.433083658869
42822.34415993753
101140.32643768121
57276.64390669586
-7143.652368234158
132930.9663188172
336747.9537838553
4260.751665304776
-26003.89331395786
718511.1662572375
176537.3416375845
-37308.63370091821
-101709.2961304453

// -----  metrics on test data

val pred = bestmodel.transform(testData)

val bceval = new RegressionEvaluator()

bceval.setMetricName("rmse").evaluate(pred)
res22: Double = 836569.5119744643

bceval.setMetricName("r2").evaluate(pred)
res23: Double = 0.6335167802658529

