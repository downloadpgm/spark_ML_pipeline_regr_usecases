
val df = spark.read.format("csv").option("header","true").option("inferSchema","true").load("spark/bike/hour.csv")

df.printSchema
root
 |-- instant: integer (nullable = true)
 |-- dteday: timestamp (nullable = true)
 |-- season: integer (nullable = true)
 |-- yr: integer (nullable = true)
 |-- mnth: integer (nullable = true)
 |-- hr: integer (nullable = true)
 |-- holiday: integer (nullable = true)
 |-- weekday: integer (nullable = true)
 |-- workingday: integer (nullable = true)
 |-- weathersit: integer (nullable = true)
 |-- temp: double (nullable = true)
 |-- atemp: double (nullable = true)
 |-- hum: double (nullable = true)
 |-- windspeed: double (nullable = true)
 |-- casual: integer (nullable = true)
 |-- registered: integer (nullable = true)
 |-- cnt: integer (nullable = true)
 
import org.apache.spark.sql.types._

val df1 = df.drop("instant","casual","registered").
withColumn("season",'season.cast(DoubleType)).
withColumn("mnth",'mnth.cast(DoubleType)).
withColumn("hr",'hr.cast(DoubleType)).
withColumn("holiday",'holiday.cast(DoubleType)).
withColumn("weekday",'weekday.cast(DoubleType)).
withColumn("workingday",'workingday.cast(DoubleType)).
withColumn("weathersit",'weathersit.cast(DoubleType)).
withColumn("tod", when(col("hr") >= 5 && col("hr") < 12, "morning" ).
                   when(col("hr") >=12 and col("hr") < 17, "afternoon").
                   when(col("hr") >=17 and col("hr") < 21, "evening").
                   otherwise("night"))

df1.printSchema
root
 |-- dteday: timestamp (nullable = true)
 |-- season: double (nullable = true)
 |-- yr: integer (nullable = true)
 |-- mnth: double (nullable = true)
 |-- hr: double (nullable = true)
 |-- holiday: double (nullable = true)
 |-- weekday: double (nullable = true)
 |-- workingday: double (nullable = true)
 |-- weathersit: double (nullable = true)
 |-- temp: double (nullable = true)
 |-- atemp: double (nullable = true)
 |-- hum: double (nullable = true)
 |-- windspeed: double (nullable = true)
 |-- cnt: integer (nullable = true)
 |-- tod: string (nullable = false)

df1.show(10)
+-------------------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+-------+
|             dteday|season| yr|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed|cnt|    tod|
+-------------------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+-------+
|2011-01-01 00:00:00|   1.0|  0| 1.0|0.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.81|      0.0| 16|  night|
|2011-01-01 00:00:00|   1.0|  0| 1.0|1.0|    0.0|    6.0|       0.0|       1.0|0.22|0.2727| 0.8|      0.0| 40|  night|
|2011-01-01 00:00:00|   1.0|  0| 1.0|2.0|    0.0|    6.0|       0.0|       1.0|0.22|0.2727| 0.8|      0.0| 32|  night|
|2011-01-01 00:00:00|   1.0|  0| 1.0|3.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.75|      0.0| 13|  night|
|2011-01-01 00:00:00|   1.0|  0| 1.0|4.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.75|      0.0|  1|  night|
|2011-01-01 00:00:00|   1.0|  0| 1.0|5.0|    0.0|    6.0|       0.0|       2.0|0.24|0.2576|0.75|   0.0896|  1|morning|
|2011-01-01 00:00:00|   1.0|  0| 1.0|6.0|    0.0|    6.0|       0.0|       1.0|0.22|0.2727| 0.8|      0.0|  2|morning|
|2011-01-01 00:00:00|   1.0|  0| 1.0|7.0|    0.0|    6.0|       0.0|       1.0| 0.2|0.2576|0.86|      0.0|  3|morning|
|2011-01-01 00:00:00|   1.0|  0| 1.0|8.0|    0.0|    6.0|       0.0|       1.0|0.24|0.2879|0.75|      0.0|  8|morning|
|2011-01-01 00:00:00|   1.0|  0| 1.0|9.0|    0.0|    6.0|       0.0|       1.0|0.32|0.3485|0.76|      0.0| 14|morning|
+-------------------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+-------+
only showing top 10 rows

df1.describe().show
+-------+------------------+------------------+------------------+------------------+--------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+------------------+---------+
|summary|            season|                yr|              mnth|                hr|             holiday|          weekday|        workingday|        weathersit|               temp|             atemp|                hum|          windspeed|               cnt|      tod|
+-------+------------------+------------------+------------------+------------------+--------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+------------------+---------+
|  count|             17379|             17379|             17379|             17379|               17379|            17379|             17379|             17379|              17379|             17379|              17379|              17379|             17379|    17379|
|   mean|2.5016399102364923|0.5025605615973301| 6.537775476149376|11.546751826917545|0.028770355026181024|3.003682605443351|0.6827205247712756| 1.425283387997008| 0.4969871684216586|0.4757751021347581| 0.6272288394038822| 0.1900976063064631|189.46308763450142|     null|
| stddev|  1.10691813944808|0.5000078290910193|3.4387757137501724|6.9144050952644776|  0.1671652763843717|2.005771456110986|0.4654306335238818|0.6393568777542525|0.19255612124972202|0.1718502156353594|0.19292983406291458|0.12234022857279034| 181.3875990918646|     null|
|    min|               1.0|                 0|               1.0|               0.0|                 0.0|              0.0|               0.0|               1.0|               0.02|               0.0|                0.0|                0.0|                 1|afternoon|
|    max|               4.0|                 1|              12.0|              23.0|                 1.0|              6.0|               1.0|               4.0|                1.0|               1.0|                1.0|             0.8507|               977|    night|
+-------+------------------+------------------+------------------+------------------+--------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+-------------------+------------------+---------+

val df2 = df1.groupBy('season,'yr,'mnth,'tod,'holiday,'weekday,'workingday,'weathersit).agg(avg('temp).as("avg_temp"),avg('atemp).as("avg_atemp"),avg('hum).as("avg_hum"),avg('windspeed).as("avg_windspeed"),sum('cnt).as("total_cnt"))

df2.printSchema
root
 |-- season: double (nullable = true)
 |-- yr: integer (nullable = true)
 |-- mnth: double (nullable = true)
 |-- tod: string (nullable = false)
 |-- holiday: double (nullable = true)
 |-- weekday: double (nullable = true)
 |-- workingday: double (nullable = true)
 |-- weathersit: double (nullable = true)
 |-- avg_temp: double (nullable = true)
 |-- avg_atemp: double (nullable = true)
 |-- avg_hum: double (nullable = true)
 |-- avg_windspeed: double (nullable = true)
 |-- total_cnt: long (nullable = true)
 
df2.show(10)
+------+---+----+---------+-------+-------+----------+----------+-------------------+-------------------+------------------+-------------------+---------+
|season| yr|mnth|      tod|holiday|weekday|workingday|weathersit|           avg_temp|          avg_atemp|           avg_hum|      avg_windspeed|total_cnt|
+------+---+----+---------+-------+-------+----------+----------+-------------------+-------------------+------------------+-------------------+---------+
|   2.0|  0| 3.0|  evening|    0.0|    0.0|       0.0|       1.0|                0.3|           0.287875|            0.3275|            0.20895|      456|
|   2.0|  0| 4.0|  morning|    0.0|    2.0|       1.0|       2.0| 0.5072727272727273| 0.4903636363636364|0.7109090909090908| 0.1831818181818182|     1204|
|   2.0|  0| 4.0|  morning|    0.0|    4.0|       1.0|       1.0| 0.4033333333333334|           0.398975|            0.6175|            0.18035|     1603|
|   3.0|  0| 7.0|afternoon|    0.0|    4.0|       1.0|       1.0| 0.8389473684210527| 0.7878684210526318|0.4378947368421053| 0.2325157894736842|     3416|
|   4.0|  0| 9.0|  evening|    0.0|    5.0|       1.0|       2.0|                0.6|                0.5|               1.0|                0.0|       99|
|   1.0|  1| 1.0|    night|    0.0|    1.0|       1.0|       2.0|0.22166666666666665|0.24368333333333334|0.8458333333333333|0.14429166666666668|      455|
|   1.0|  1| 1.0|    night|    0.0|    5.0|       1.0|       2.0|0.33999999999999997| 0.3451222222222222|0.7022222222222223| 0.2504222222222222|      336|
|   2.0|  1| 3.0|  morning|    0.0|    6.0|       0.0|       2.0|0.45500000000000007|0.44317499999999993|0.8549999999999999|0.16914166666666666|     1871|
|   3.0|  1| 7.0|    night|    0.0|    5.0|       1.0|       3.0|               0.64|            0.58335|              0.86|0.20900000000000002|      156|
|   4.0|  1|10.0|afternoon|    0.0|    2.0|       1.0|       3.0|0.43428571428571416|0.40044285714285716|              0.85|0.23238571428571433|     1210|
+------+---+----+---------+-------+-------+----------+----------+-------------------+-------------------+------------------+-------------------+---------+
only showing top 10 rows


val df3 = df2.withColumn("label",'total_cnt.cast(DoubleType))


import org.apache.spark.ml.feature.{StringIndexer, OneHotEncoder, VectorAssembler}

val dfInd3 = new StringIndexer().setInputCol("tod").setOutputCol("todCat")

val dfOne1 = new OneHotEncoder().setInputCol("season").setOutputCol("seasonVect")
val dfOne2 = new OneHotEncoder().setInputCol("mnth").setOutputCol("mnthVect")
val dfOne3 = new OneHotEncoder().setInputCol("todCat").setOutputCol("todVect")
val dfOne4 = new OneHotEncoder().setInputCol("weekday").setOutputCol("weekdayVect")

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("season","mnth","todCat","holiday","weekday","workingday","weathersit","avg_temp","avg_atemp","avg_hum","avg_windspeed"))

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(dfInd3,va))

val df4 = pipeline.fit(df3).transform(df3)

df4.printSchema
root
 |-- season: double (nullable = true)
 |-- yr: integer (nullable = true)
 |-- mnth: double (nullable = true)
 |-- tod: string (nullable = false)
 |-- holiday: double (nullable = true)
 |-- weekday: double (nullable = true)
 |-- workingday: double (nullable = true)
 |-- weathersit: double (nullable = true)
 |-- avg_temp: double (nullable = true)
 |-- avg_atemp: double (nullable = true)
 |-- avg_hum: double (nullable = true)
 |-- avg_windspeed: double (nullable = true)
 |-- total_cnt: long (nullable = true)
 |-- label: double (nullable = true)
 |-- todCat: double (nullable = false)
 |-- features: vector (nullable = true)
 
df4.select("label","features").show(10,false)
+------+------------------------------------------------------------------------------------------------------------+
|label |features                                                                                                    |
+------+------------------------------------------------------------------------------------------------------------+
|456.0 |[2.0,3.0,3.0,0.0,0.0,0.0,1.0,0.3,0.287875,0.3275,0.20895]                                                   |
|1204.0|[2.0,4.0,1.0,0.0,2.0,1.0,2.0,0.5072727272727273,0.4903636363636364,0.7109090909090908,0.1831818181818182]   |
|1603.0|[2.0,4.0,1.0,0.0,4.0,1.0,1.0,0.4033333333333334,0.398975,0.6175,0.18035]                                    |
|3416.0|[3.0,7.0,2.0,0.0,4.0,1.0,1.0,0.8389473684210527,0.7878684210526318,0.4378947368421053,0.2325157894736842]   |
|99.0  |[4.0,9.0,3.0,0.0,5.0,1.0,2.0,0.6,0.5,1.0,0.0]                                                               |
|455.0 |[1.0,1.0,0.0,0.0,1.0,1.0,2.0,0.22166666666666665,0.24368333333333334,0.8458333333333333,0.14429166666666668]|
|336.0 |[1.0,1.0,0.0,0.0,5.0,1.0,2.0,0.33999999999999997,0.3451222222222222,0.7022222222222223,0.2504222222222222]  |
|1871.0|[2.0,3.0,1.0,0.0,6.0,0.0,2.0,0.45500000000000007,0.44317499999999993,0.8549999999999999,0.16914166666666666]|
|156.0 |[3.0,7.0,0.0,0.0,5.0,1.0,3.0,0.64,0.58335,0.86,0.20900000000000002]                                         |
|1210.0|[4.0,10.0,2.0,0.0,2.0,1.0,3.0,0.43428571428571416,0.40044285714285716,0.85,0.23238571428571433]             |
+------+------------------------------------------------------------------------------------------------------------+
only showing top 10 rows


// calculate pearson correlation to check multicolinearity

import org.apache.spark.ml.stat.Correlation
import org.apache.spark.ml.linalg.Matrix
import org.apache.spark.sql.Row

val corr = Correlation.corr(df4, "features", "pearson").head match {
   case Row(coeff: Matrix) => coeff
}
corr: org.apache.spark.ml.linalg.Matrix =
1.0                     0.7436590286175474     ... (11 total)
0.7436590286175474      1.0                    ...
0.011517783622580862    0.011546417049060271   ...
-0.0038586989931636393  0.02333193810888879    ...
-0.021217788484057223   0.002543465830437292   ...
0.02139456338328504     0.013756326772584442   ...
-0.03253137993368341    -0.022477742366970272  ...
0.37481162962914416     0.1933476145312041     ...
0.380438899915024       0.19779582999327822    ...
0.1286737891644245      0.14613128013279825    ...
-0.17605539750779156    -0.14740724970640742   ...


corr.toDense.rowIter.foreach( x => {
  val size = x.size
  for ( i <- Range(0,size)) { 
    val elem = x(i)
    print(f"$elem%.3f\t") 
  }
  println
})
// "season","mnth","todCat","holiday","weekday","workingday","weathersit","avg_temp","avg_atemp","avg_hum","avg_windspeed"
1.000   0.744   0.012   -0.004  -0.021  0.021   -0.033  0.375   0.380   0.129   -0.176
0.744   1.000   0.012   0.023   0.003   0.014   -0.022  0.193   0.198   0.146   -0.147
0.012   0.012   1.000   -0.004  0.005   0.002   -0.050  0.147   0.147   -0.337  0.241
-0.004  0.023   -0.004  1.000   -0.167  -0.361  -0.069  -0.017  -0.023  -0.029  -0.007
-0.021  0.003   0.005   -0.167  1.000   0.057   0.001   -0.020  -0.027  -0.036  0.025
0.021   0.014   0.002   -0.361  0.057   1.000   0.046   0.054   0.057   0.007   -0.006
-0.033  -0.022  -0.050  -0.069  0.001   0.046   1.000   -0.082  -0.085  0.548   0.064
0.375   0.193   0.147   -0.017  -0.020  0.054   -0.082  1.000   0.994   -0.061  -0.051
0.380   0.198   0.147   -0.023  -0.027  0.057   -0.085  0.994   1.000   -0.057  -0.074
0.129   0.146   -0.337  -0.029  -0.036  0.007   0.548   -0.061  -0.057  1.000   -0.255
-0.176  -0.147  0.241   -0.007  0.025   -0.006  0.064   -0.051  -0.074  -0.255  1.000

// avg_temp x avg_atemp = 0.994 can be considered multicolinear
// avg_atemp removed from analysis

// ----- building the linear regression model

val va = new VectorAssembler().setOutputCol("features").setInputCols(Array("seasonVect","mnthVect","todVect","holiday","weekdayVect","workingday","weathersit","avg_temp","avg_hum","avg_windspeed"))

import org.apache.spark.ml.feature.StandardScaler

import org.apache.spark.ml.feature.StandardScaler
val stdScaler = new StandardScaler().
setWithStd(true).
setWithMean(true).
setInputCol("features").
setOutputCol("scaledFeatures")

import org.apache.spark.ml.regression.LinearRegression
val lr = new LinearRegression
lr.setFitIntercept(true).setFeaturesCol("scaledFeatures")

import org.apache.spark.ml.Pipeline
val pipeline = new Pipeline().setStages(Array(dfInd3,dfOne1,dfOne2,dfOne3,dfOne4,va,stdScaler,lr))

val Array(trainingData, testData) = df3.randomSplit(Array(0.7,0.3),11L)

trainingData.cache
testData.cache

// ----- find best linear regression model

import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}

val paramGrid = new ParamGridBuilder().
addGrid(lr.regParam, Array(1, 0.1, 0.01, 0.001)).
addGrid(lr.maxIter, Array(100,200,300)).build()

import org.apache.spark.ml.evaluation.RegressionEvaluator

val cv = new CrossValidator().
setEstimator(pipeline).
setEvaluator(new RegressionEvaluator).
setEstimatorParamMaps(paramGrid).
setNumFolds(3)

val model = cv.fit(trainingData)

import org.apache.spark.ml.PipelineModel
val bestmodel = model.bestModel.asInstanceOf[PipelineModel]

import org.apache.spark.ml.regression.LinearRegressionModel
val lrmodel = bestmodel.stages(7).asInstanceOf[LinearRegressionModel]

// -----  metrics extracted from model

lrmodel.getRegParam
res24: Double = 1.0

lrmodel.getMaxIter
res2: Int = 100

lrmodel.getFitIntercept
res4: Boolean = true

lrmodel.getStandardization
res5: Boolean = true

lrmodel.summary.rootMeanSquaredError
res26: Double = 1299.9018304356196

lrmodel.summary.r2
res27: Double = 0.4862328996882922

println(s"LR Model coefficients:\n${lrmodel.coefficients.toArray.mkString("\n")}")
LR Model coefficients:
0.0
57.41485166317221
224.835356136308
99.84127903336822
0.0
98.2400077689785
58.44571531174944
-170.72166673433733
-3.750185331241917
24.310116687369465
-333.87569997649393
-61.98824382358321
-11.233138898866265
-119.81409491623478
178.53980872032062
161.05457550958764
-455.85014365729984
-18.730873487900766
-174.61406540620135
-297.2019900951199
-21.65327963325743
-109.06982736099512
-6.833522027627914
-34.79705713947928
-30.67161856756583
-6.046585921698404
7.211691101161092
-740.4572120577287
645.4502759762097
-276.19834884868857
-18.347769658459192

// -----  metrics on test data

val pred = bestmodel.transform(testData)

val bceval = new RegressionEvaluator()

bceval.setMetricName("rmse").evaluate(pred)
res29: Double = 1237.5036737173723

bceval.setMetricName("r2").evaluate(pred)
res30: Double = 0.4441550337975986
